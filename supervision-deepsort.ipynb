{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":11985330,"sourceType":"datasetVersion","datasetId":7538224}],"dockerImageVersionId":31041,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"## DeepSORT","metadata":{}},{"cell_type":"code","source":"import os\n\nHOME = os.getcwd()\nprint(HOME)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-29T03:39:57.789160Z","iopub.execute_input":"2025-05-29T03:39:57.789710Z","iopub.status.idle":"2025-05-29T03:39:57.793536Z","shell.execute_reply.started":"2025-05-29T03:39:57.789687Z","shell.execute_reply":"2025-05-29T03:39:57.792848Z"}},"outputs":[{"name":"stdout","text":"/kaggle/working\n","output_type":"stream"}],"execution_count":6},{"cell_type":"code","source":"!pip install deep_sort_realtime\n!pip install supervision\n!pip install ultralytics\n\nfrom IPython import display\ndisplay.clear_output()\n\nfrom deep_sort_realtime.deepsort_tracker import DeepSort\nimport numpy as np\nimport supervision as sv","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-29T03:37:00.886261Z","iopub.execute_input":"2025-05-29T03:37:00.887007Z","iopub.status.idle":"2025-05-29T03:38:21.844493Z","shell.execute_reply.started":"2025-05-29T03:37:00.886976Z","shell.execute_reply":"2025-05-29T03:38:21.843762Z"}},"outputs":[],"execution_count":4},{"cell_type":"code","source":"CLASS_NAMES_DICT = model.model.names\n# SELECTED_CLASS_NAMES = ['car', 'truck', 'bus', 'motorcycle']\nSELECTED_CLASS_NAMES = ['person']\nSELECTED_CLASS_IDS = [{value: key for key, value in CLASS_NAMES_DICT.items()}[class_name] for class_name in SELECTED_CLASS_NAMES]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-29T03:48:06.913434Z","iopub.execute_input":"2025-05-29T03:48:06.914058Z","iopub.status.idle":"2025-05-29T03:48:06.918012Z","shell.execute_reply.started":"2025-05-29T03:48:06.914033Z","shell.execute_reply":"2025-05-29T03:48:06.917177Z"}},"outputs":[],"execution_count":28},{"cell_type":"code","source":"from ultralytics import YOLO\n\nmodel = YOLO('yolov8s.pt')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-29T03:47:22.155346Z","iopub.execute_input":"2025-05-29T03:47:22.155656Z","iopub.status.idle":"2025-05-29T03:47:25.694818Z","shell.execute_reply.started":"2025-05-29T03:47:22.155633Z","shell.execute_reply":"2025-05-29T03:47:25.694010Z"}},"outputs":[{"name":"stdout","text":"Creating new Ultralytics Settings v0.0.6 file ✅ \nView Ultralytics Settings with 'yolo settings' or at '/root/.config/Ultralytics/settings.json'\nUpdate Settings with 'yolo settings key=value', i.e. 'yolo settings runs_dir=path/to/dir'. For help see https://docs.ultralytics.com/quickstart/#ultralytics-settings.\nDownloading https://github.com/ultralytics/assets/releases/download/v8.3.0/yolov8s.pt to 'yolov8s.pt'...\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 21.5M/21.5M [00:00<00:00, 45.2MB/s]\n","output_type":"stream"}],"execution_count":26},{"cell_type":"code","source":"SOURCE_VIDEO_PATH = '/kaggle/input/people-walking-resolution/people-walking.mp4'\nTARGET_VIDEO_PATH = f\"{HOME}/result_DeepSORT.mp4\"\n\n# Initialize the DeepSORT tracker with custom parameters\ndeep_sort_tracker = DeepSort(\n    max_age=30,           # Number of frames to keep a lost track before removing it\n    n_init=3,             # Minimum number of detections before a track is confirmed\n    max_cosine_distance=0.2  # Cosine distance threshold for feature matching\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-29T03:46:46.062688Z","iopub.execute_input":"2025-05-29T03:46:46.063279Z","iopub.status.idle":"2025-05-29T03:46:46.170935Z","shell.execute_reply.started":"2025-05-29T03:46:46.063255Z","shell.execute_reply":"2025-05-29T03:46:46.170336Z"}},"outputs":[],"execution_count":21},{"cell_type":"code","source":"# Define the start and end point for the line used in zone tracking\nLINE_START = sv.Point(0, 540)\nLINE_END = sv.Point(1920, 540)  # Assuming video width is 3840","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-29T03:46:46.287297Z","iopub.execute_input":"2025-05-29T03:46:46.288187Z","iopub.status.idle":"2025-05-29T03:46:46.291558Z","shell.execute_reply.started":"2025-05-29T03:46:46.288163Z","shell.execute_reply":"2025-05-29T03:46:46.290815Z"}},"outputs":[],"execution_count":22},{"cell_type":"code","source":"# Create an instance of BoxAnnotator to draw bounding boxes around detected objects\nbox_annotator = sv.BoxAnnotator(thickness=4)\n\n# Create an instance of LabelAnnotator to display text labels on detected objects\nlabel_annotator = sv.LabelAnnotator(text_thickness=2, text_scale=1.5, text_color=sv.Color.BLACK)\n\n# Create an instance of TraceAnnotator to visualize object movement traces\ntrace_annotator = sv.TraceAnnotator(thickness=4, trace_length=50)\n\n# Create an instance of LineZoneAnnotator to visualize and annotate line-based object tracking\nline_zone_annotator = sv.LineZoneAnnotator(thickness=4, text_thickness=4, text_scale=2)\n\n# Define a LineZone for tracking objects crossing a specific line\nline_zone = sv.LineZone(start=LINE_START, end=LINE_END)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-29T03:46:46.503777Z","iopub.execute_input":"2025-05-29T03:46:46.504013Z","iopub.status.idle":"2025-05-29T03:46:46.508522Z","shell.execute_reply.started":"2025-05-29T03:46:46.503998Z","shell.execute_reply":"2025-05-29T03:46:46.507787Z"}},"outputs":[],"execution_count":23},{"cell_type":"code","source":"def callback(frame: np.ndarray, index: int) -> np.ndarray:\n    # Run the YOLO model on the input frame to detect objects\n    results = model(frame, verbose=False)[0]\n\n    # Convert YOLO detection results into a Supervision Detections object\n    detections = sv.Detections.from_ultralytics(results)\n\n    # Filter detections to retain only selected classes (car, motorcycle, bus, truck)\n    detections = detections[np.isin(detections.class_id, SELECTED_CLASS_IDS)]\n\n    # Convert detections into DeepSORT-compatible format (bbox, confidence, class_name)\n    ds_detections = []\n    for bbox, conf, class_id in zip(detections.xyxy, detections.confidence, detections.class_id):\n        class_name = CLASS_NAMES_DICT.get(class_id, \"Unknown\")  # Retrieve class name from ID\n        left, top, xmax, ymax = bbox  # Extract bounding box coordinates\n        width, height = xmax - left, ymax - top  # Compute width and height\n        ds_detections.append(([left, top, width, height], float(conf), class_name))\n    \n    # Update the DeepSORT tracker with the new detections\n    tracks = deep_sort_tracker.update_tracks(ds_detections, frame=frame)\n    \n    # Initialize lists to store tracked object details\n    tracked_bboxes = []\n    tracked_confidences = []\n    tracked_class_ids = []\n    tracked_ids = []\n    \n    # Iterate through tracked objects and extract relevant information\n    for track in tracks:\n        if not track.is_confirmed():  # Ignore unconfirmed tracks\n            continue\n    \n        track_id = track.track_id  # Retrieve track ID\n        bbox = track.to_ltrb()  # Convert bbox format for tracking\n        conf = track.det_conf if hasattr(track, 'det_conf') else 1.0  # Retrieve detection confidence\n        class_name = track.get_det_class() or \"Unknown\"  # Retrieve class name\n        class_id = {value: key for key, value in CLASS_NAMES_DICT.items()}.get(class_name, None)\n    \n        # Assign a default class ID if not found\n        if class_id is None:\n            class_id = 0\n    \n        # Store tracking details for visualization\n        tracked_bboxes.append(bbox)\n        tracked_confidences.append(conf)\n        tracked_class_ids.append(class_id)\n        tracked_ids.append(track_id)\n    \n    # Create a Supervision Detections object for tracked objects\n    if len(tracked_bboxes) > 0:\n        tracked_detections = sv.Detections(\n            xyxy=np.array(tracked_bboxes, dtype=np.float32).reshape(-1, 4),\n            confidence=np.array(tracked_confidences, dtype=np.float32),\n            class_id=np.array(tracked_class_ids, dtype=np.int32),\n            tracker_id=np.array(tracked_ids, dtype=np.int32)\n        )\n    else:\n        # Handle cases where no objects are detected or tracked\n        tracked_detections = sv.Detections(\n            xyxy=np.zeros((0, 4), dtype=np.float32),\n            confidence=np.array([], dtype=np.float32),\n            class_id=np.array([], dtype=np.int32),\n            tracker_id=np.array([], dtype=np.int32)\n        )\n    \n    # Generate labels for tracked objects with ID and class name\n    labels = [\n        f\"#{tracker_id} {CLASS_NAMES_DICT.get(class_id, 'Unknown')}\"\n        for tracker_id, class_id in zip(tracked_ids, tracked_class_ids)\n    ]\n\n    # Copy the frame to apply annotations\n    annotated_frame = frame.copy()\n    \n    # Apply trace annotations to visualize object movement history\n    annotated_frame = trace_annotator.annotate(scene=annotated_frame, detections=tracked_detections)\n    \n    # Draw bounding boxes around tracked objects\n    annotated_frame = box_annotator.annotate(scene=annotated_frame, detections=tracked_detections)\n    \n    # Display labels containing tracker IDs and class names\n    annotated_frame = label_annotator.annotate(scene=annotated_frame, detections=tracked_detections, labels=labels)\n    \n    # Trigger the line zone when objects cross it\n    line_zone.trigger(tracked_detections)\n    \n    # Annotate the line zone with object counts and return the final frame\n    return line_zone_annotator.annotate(annotated_frame, line_counter=line_zone)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-29T03:46:08.140318Z","iopub.execute_input":"2025-05-29T03:46:08.140945Z","iopub.status.idle":"2025-05-29T03:46:08.151015Z","shell.execute_reply.started":"2025-05-29T03:46:08.140921Z","shell.execute_reply":"2025-05-29T03:46:08.150458Z"}},"outputs":[],"execution_count":19},{"cell_type":"code","source":"sv.process_video(\n    source_path=SOURCE_VIDEO_PATH,\n    target_path=TARGET_VIDEO_PATH,\n    callback=callback\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-29T03:48:22.865771Z","iopub.execute_input":"2025-05-29T03:48:22.866325Z","iopub.status.idle":"2025-05-29T03:49:40.952709Z","shell.execute_reply.started":"2025-05-29T03:48:22.866303Z","shell.execute_reply":"2025-05-29T03:49:40.950232Z"}},"outputs":[],"execution_count":29}]}